{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade Finance Automation with Document AI\n",
    "\n",
    "## Use Case Overview\n",
    "\n",
    "**Business Problem:** Oil & Gas refiners process hundreds of trade documents:\n",
    "- **Letters of Credit (LCs)**: Payment guarantees for crude imports\n",
    "- **Bills of Lading**: Shipping documents\n",
    "- **Invoices**: Commercial invoices from suppliers\n",
    "- **Certificates**: Quality, origin, insurance certificates\n",
    "\n",
    "**Manual Processing Challenges:**\n",
    "- 60-70% of LCs have discrepancies on first presentation\n",
    "- Average 3-5 days to process a document set\n",
    "- $150-500 per discrepancy handling cost\n",
    "\n",
    "**AI Applications:**\n",
    "1. OCR for document digitization\n",
    "2. Named Entity Recognition (NER) for field extraction\n",
    "3. Cross-document validation\n",
    "4. Discrepancy prediction and auto-correction\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Simulate trade finance documents\n",
    "2. Build OCR/extraction pipeline (simulated)\n",
    "3. Create document validation engine\n",
    "4. Implement discrepancy detection\n",
    "5. Build processing dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.treasury_sim.generators import generate_trade_documents, set_seed\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Trade Documents\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **What documents are in a typical LC presentation?**\n",
    "> \n",
    "> 1. **Letter of Credit**: The bank's payment guarantee\n",
    "> 2. **Commercial Invoice**: Details of goods and pricing\n",
    "> 3. **Bill of Lading**: Proof of shipment\n",
    "> 4. **Certificate of Origin**: Country of origin\n",
    "> 5. **Quality Certificate**: Product specifications\n",
    "> 6. **Insurance Certificate**: Cargo insurance\n",
    ">\n",
    "> All documents must be **consistent** - any mismatch is a \"discrepancy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# Generate trade documents\n",
    "documents = generate_trade_documents(n_transactions=100, seed=42)\n",
    "\n",
    "print(f\"ðŸ“Š Generated {len(documents):,} documents\")\n",
    "print(f\"\\nDocument Types: {documents['document_type'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview documents\n",
    "documents.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulated OCR & Document Extraction\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **How does Document AI work?**\n",
    "> \n",
    "> 1. **OCR Layer**: Converts scanned documents to text\n",
    ">    - Azure Form Recognizer, AWS Textract, Google Document AI\n",
    "> \n",
    "> 2. **NER/Extraction Layer**: Identifies key fields\n",
    ">    - Amount, date, beneficiary, goods description\n",
    "> \n",
    "> 3. **Confidence Scores**: Each extraction has confidence\n",
    ">    - High confidence (>0.95): Auto-accept\n",
    ">    - Medium (0.80-0.95): Review flag\n",
    ">    - Low (<0.80): Manual review required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentExtractor:\n",
    "    \"\"\"\n",
    "    Simulates OCR and field extraction from trade documents.\n",
    "    In production, this would use Azure Form Recognizer or similar.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.extraction_rules = {\n",
    "            'LC': ['lc_number', 'amount', 'currency', 'beneficiary', 'applicant', \n",
    "                   'expiry_date', 'latest_shipment_date', 'goods_description'],\n",
    "            'INVOICE': ['invoice_number', 'amount', 'currency', 'seller', 'buyer',\n",
    "                        'goods_description', 'quantity', 'unit_price'],\n",
    "            'BILL_OF_LADING': ['bl_number', 'vessel', 'port_of_loading', 'port_of_discharge',\n",
    "                               'shipper', 'consignee', 'goods_description', 'quantity'],\n",
    "            'CERTIFICATE_OF_ORIGIN': ['cert_number', 'country_of_origin', 'exporter',\n",
    "                                       'goods_description', 'quantity'],\n",
    "            'QUALITY_CERTIFICATE': ['cert_number', 'product_name', 'api_gravity', \n",
    "                                     'sulfur_content', 'inspection_date'],\n",
    "            'INSURANCE_CERTIFICATE': ['policy_number', 'insured_amount', 'coverage_type',\n",
    "                                       'voyage_from', 'voyage_to']\n",
    "        }\n",
    "    \n",
    "    def extract(self, document_row):\n",
    "        \"\"\"\n",
    "        Simulate extraction from a document.\n",
    "        Returns extracted fields with confidence scores.\n",
    "        \"\"\"\n",
    "        doc_type = document_row['document_type']\n",
    "        fields = self.extraction_rules.get(doc_type, [])\n",
    "        \n",
    "        # Simulate extraction with varying confidence\n",
    "        extracted = {\n",
    "            'document_id': document_row['document_id'],\n",
    "            'document_type': doc_type,\n",
    "            'transaction_id': document_row['transaction_id'],\n",
    "            'fields': {}\n",
    "        }\n",
    "        \n",
    "        base_confidence = document_row.get('ocr_confidence', 0.95)\n",
    "        \n",
    "        for field in fields:\n",
    "            # Simulate field-level confidence (varies by field type)\n",
    "            if field in ['amount', 'currency', 'lc_number', 'bl_number']:\n",
    "                # Structured fields - higher confidence\n",
    "                confidence = min(base_confidence + np.random.uniform(0, 0.05), 1.0)\n",
    "            elif field in ['goods_description', 'beneficiary', 'consignee']:\n",
    "                # Text fields - lower confidence\n",
    "                confidence = base_confidence - np.random.uniform(0, 0.15)\n",
    "            else:\n",
    "                confidence = base_confidence + np.random.uniform(-0.1, 0.05)\n",
    "            \n",
    "            # Get value from document (simulate extraction)\n",
    "            if field == 'amount':\n",
    "                value = document_row['amount']\n",
    "            elif field == 'currency':\n",
    "                value = document_row['currency']\n",
    "            elif field == 'goods_description':\n",
    "                value = document_row['goods_description']\n",
    "            elif field == 'quantity':\n",
    "                value = document_row['quantity']\n",
    "            else:\n",
    "                # Generate placeholder for other fields\n",
    "                value = f\"{field.upper()}_{document_row['transaction_id'][:8]}\"\n",
    "            \n",
    "            extracted['fields'][field] = {\n",
    "                'value': value,\n",
    "                'confidence': round(confidence, 3)\n",
    "            }\n",
    "        \n",
    "        return extracted\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = DocumentExtractor()\n",
    "\n",
    "# Extract from all documents\n",
    "extractions = [extractor.extract(row) for _, row in documents.iterrows()]\n",
    "\n",
    "print(f\"âœ… Extracted fields from {len(extractions)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example extraction\n",
    "import json\n",
    "\n",
    "print(\"ðŸ“„ SAMPLE EXTRACTION (Letter of Credit)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find an LC\n",
    "lc_extraction = next(e for e in extractions if e['document_type'] == 'LC')\n",
    "print(json.dumps(lc_extraction, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze extraction confidence\n",
    "confidence_data = []\n",
    "for ext in extractions:\n",
    "    for field, data in ext['fields'].items():\n",
    "        confidence_data.append({\n",
    "            'document_type': ext['document_type'],\n",
    "            'field': field,\n",
    "            'confidence': data['confidence']\n",
    "        })\n",
    "\n",
    "confidence_df = pd.DataFrame(confidence_data)\n",
    "\n",
    "# Confidence by document type\n",
    "fig = px.box(confidence_df, x='document_type', y='confidence', color='document_type',\n",
    "             title='Extraction Confidence by Document Type')\n",
    "fig.add_hline(y=0.95, line_dash=\"dash\", line_color=\"green\", annotation_text=\"Auto-accept\")\n",
    "fig.add_hline(y=0.80, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Manual review\")\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Validation Engine\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **What makes LC documents compliant?**\n",
    "> \n",
    "> Key validation rules (UCP 600):\n",
    "> 1. **Amount consistency**: Invoice â‰¤ LC amount\n",
    "> 2. **Goods description**: Must match LC terms exactly\n",
    "> 3. **Dates**: Documents within validity period\n",
    "> 4. **Quantities**: B/L quantity matches invoice (Â±5% tolerance)\n",
    "> 5. **Parties**: Names must match exactly\n",
    "> 6. **Ports**: Must match LC requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentValidator:\n",
    "    \"\"\"\n",
    "    Validates trade documents against LC requirements.\n",
    "    Detects discrepancies that could cause payment rejection.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules = [\n",
    "            ('amount_match', self._check_amount_match),\n",
    "            ('quantity_tolerance', self._check_quantity_tolerance),\n",
    "            ('goods_description', self._check_goods_description),\n",
    "            ('date_validity', self._check_date_validity),\n",
    "            ('currency_match', self._check_currency_match)\n",
    "        ]\n",
    "        \n",
    "    def _check_amount_match(self, docs_group):\n",
    "        \"\"\"Invoice amount must not exceed LC amount\"\"\"\n",
    "        lc = docs_group[docs_group['document_type'] == 'LC']\n",
    "        invoice = docs_group[docs_group['document_type'] == 'INVOICE']\n",
    "        \n",
    "        if lc.empty or invoice.empty:\n",
    "            return None\n",
    "            \n",
    "        lc_amount = lc['amount'].iloc[0]\n",
    "        inv_amount = invoice['amount'].iloc[0]\n",
    "        \n",
    "        if inv_amount > lc_amount:\n",
    "            return {\n",
    "                'rule': 'amount_match',\n",
    "                'severity': 'HIGH',\n",
    "                'message': f'Invoice amount ({inv_amount:,.0f}) exceeds LC amount ({lc_amount:,.0f})',\n",
    "                'auto_fixable': False\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def _check_quantity_tolerance(self, docs_group):\n",
    "        \"\"\"B/L quantity must be within Â±5% of invoice\"\"\"\n",
    "        invoice = docs_group[docs_group['document_type'] == 'INVOICE']\n",
    "        bl = docs_group[docs_group['document_type'] == 'BILL_OF_LADING']\n",
    "        \n",
    "        if invoice.empty or bl.empty:\n",
    "            return None\n",
    "            \n",
    "        inv_qty = invoice['quantity'].iloc[0]\n",
    "        bl_qty = bl['quantity'].iloc[0]\n",
    "        \n",
    "        tolerance = abs(bl_qty - inv_qty) / inv_qty\n",
    "        \n",
    "        if tolerance > 0.05:  # 5% tolerance\n",
    "            return {\n",
    "                'rule': 'quantity_tolerance',\n",
    "                'severity': 'MEDIUM',\n",
    "                'message': f'Quantity mismatch: Invoice ({inv_qty:,.0f}) vs B/L ({bl_qty:,.0f}) = {tolerance:.1%}',\n",
    "                'auto_fixable': True  # Can request amendment\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def _check_goods_description(self, docs_group):\n",
    "        \"\"\"Goods description must match across documents\"\"\"\n",
    "        descriptions = docs_group['goods_description'].unique()\n",
    "        \n",
    "        if len(descriptions) > 1:\n",
    "            return {\n",
    "                'rule': 'goods_description',\n",
    "                'severity': 'HIGH',\n",
    "                'message': f'Inconsistent goods descriptions: {list(descriptions)[:2]}',\n",
    "                'auto_fixable': False\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def _check_date_validity(self, docs_group):\n",
    "        \"\"\"Documents must be dated within validity period\"\"\"\n",
    "        lc = docs_group[docs_group['document_type'] == 'LC']\n",
    "        \n",
    "        if lc.empty:\n",
    "            return None\n",
    "            \n",
    "        # Check if any document is dated after LC expiry (simulated)\n",
    "        # In real system, would compare actual dates\n",
    "        if np.random.random() < 0.05:  # 5% chance of date issue\n",
    "            return {\n",
    "                'rule': 'date_validity',\n",
    "                'severity': 'HIGH',\n",
    "                'message': 'Document dated after LC expiry',\n",
    "                'auto_fixable': False\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def _check_currency_match(self, docs_group):\n",
    "        \"\"\"All documents must show same currency\"\"\"\n",
    "        currencies = docs_group['currency'].dropna().unique()\n",
    "        \n",
    "        if len(currencies) > 1:\n",
    "            return {\n",
    "                'rule': 'currency_match',\n",
    "                'severity': 'MEDIUM',\n",
    "                'message': f'Currency mismatch: {list(currencies)}',\n",
    "                'auto_fixable': True\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def validate(self, docs_group):\n",
    "        \"\"\"Validate a set of documents for a single transaction\"\"\"\n",
    "        discrepancies = []\n",
    "        \n",
    "        for rule_name, rule_func in self.rules:\n",
    "            result = rule_func(docs_group)\n",
    "            if result:\n",
    "                discrepancies.append(result)\n",
    "        \n",
    "        return {\n",
    "            'transaction_id': docs_group['transaction_id'].iloc[0],\n",
    "            'n_documents': len(docs_group),\n",
    "            'is_compliant': len(discrepancies) == 0,\n",
    "            'discrepancies': discrepancies,\n",
    "            'n_discrepancies': len(discrepancies),\n",
    "            'severity_max': max([d['severity'] for d in discrepancies], default='NONE')\n",
    "        }\n",
    "\n",
    "# Initialize validator\n",
    "validator = DocumentValidator()\n",
    "\n",
    "# Validate all transactions\n",
    "validation_results = []\n",
    "for txn_id in documents['transaction_id'].unique():\n",
    "    txn_docs = documents[documents['transaction_id'] == txn_id]\n",
    "    result = validator.validate(txn_docs)\n",
    "    validation_results.append(result)\n",
    "\n",
    "validation_df = pd.DataFrame(validation_results)\n",
    "\n",
    "print(\"ðŸ“Š VALIDATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Transactions: {len(validation_df)}\")\n",
    "print(f\"Compliant: {validation_df['is_compliant'].sum()} ({validation_df['is_compliant'].mean()*100:.1f}%)\")\n",
    "print(f\"With Discrepancies: {(~validation_df['is_compliant']).sum()}\")\n",
    "print(f\"\\nDiscrepancy Distribution:\")\n",
    "print(validation_df['n_discrepancies'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze discrepancies\n",
    "all_discrepancies = []\n",
    "for result in validation_results:\n",
    "    for disc in result['discrepancies']:\n",
    "        disc['transaction_id'] = result['transaction_id']\n",
    "        all_discrepancies.append(disc)\n",
    "\n",
    "if all_discrepancies:\n",
    "    disc_df = pd.DataFrame(all_discrepancies)\n",
    "    \n",
    "    # Discrepancy breakdown\n",
    "    fig = make_subplots(rows=1, cols=2,\n",
    "        subplot_titles=('Discrepancies by Rule', 'Discrepancies by Severity'),\n",
    "        specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}]])\n",
    "    \n",
    "    # By rule\n",
    "    rule_counts = disc_df['rule'].value_counts()\n",
    "    fig.add_trace(go.Pie(labels=rule_counts.index, values=rule_counts.values), row=1, col=1)\n",
    "    \n",
    "    # By severity\n",
    "    sev_counts = disc_df['severity'].value_counts()\n",
    "    colors = {'HIGH': 'red', 'MEDIUM': 'orange', 'LOW': 'yellow'}\n",
    "    fig.add_trace(go.Pie(labels=sev_counts.index, values=sev_counts.values,\n",
    "                         marker_colors=[colors.get(s, 'gray') for s in sev_counts.index]), \n",
    "                  row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(height=350, title_text='Discrepancy Analysis')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"âœ… No discrepancies found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AI-Powered Discrepancy Resolution\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **How can AI help resolve discrepancies?**\n",
    "> \n",
    "> 1. **Classification**: Categorize discrepancy type\n",
    "> 2. **Resolution Recommendation**: Suggest corrective action\n",
    "> 3. **Auto-fix**: Apply corrections for minor issues\n",
    "> 4. **Escalation**: Route complex issues to specialists\n",
    "> 5. **Learning**: Track resolution patterns for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscrepancyResolver:\n",
    "    \"\"\"\n",
    "    AI-powered discrepancy resolution assistant.\n",
    "    Recommends actions and tracks resolution patterns.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.resolution_patterns = {\n",
    "            'amount_match': {\n",
    "                'action': 'REQUEST_AMENDMENT',\n",
    "                'template': 'Request LC amendment to increase amount to {required_amount}',\n",
    "                'avg_resolution_days': 3,\n",
    "                'cost_estimate': 350\n",
    "            },\n",
    "            'quantity_tolerance': {\n",
    "                'action': 'NEGOTIATE_TOLERANCE',\n",
    "                'template': 'Request bank acceptance under +/- 5% tolerance clause',\n",
    "                'avg_resolution_days': 1,\n",
    "                'cost_estimate': 150\n",
    "            },\n",
    "            'goods_description': {\n",
    "                'action': 'REISSUE_DOCUMENT',\n",
    "                'template': 'Request supplier to reissue {document_type} with corrected description',\n",
    "                'avg_resolution_days': 4,\n",
    "                'cost_estimate': 250\n",
    "            },\n",
    "            'date_validity': {\n",
    "                'action': 'REQUEST_LC_EXTENSION',\n",
    "                'template': 'Request LC extension or accept under reserve',\n",
    "                'avg_resolution_days': 5,\n",
    "                'cost_estimate': 500\n",
    "            },\n",
    "            'currency_match': {\n",
    "                'action': 'CORRECT_DOCUMENT',\n",
    "                'template': 'Request correction of currency to {correct_currency}',\n",
    "                'avg_resolution_days': 2,\n",
    "                'cost_estimate': 100\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def recommend_resolution(self, discrepancy):\n",
    "        \"\"\"Recommend resolution for a discrepancy\"\"\"\n",
    "        rule = discrepancy['rule']\n",
    "        pattern = self.resolution_patterns.get(rule, {\n",
    "            'action': 'MANUAL_REVIEW',\n",
    "            'template': 'Escalate to trade finance specialist',\n",
    "            'avg_resolution_days': 7,\n",
    "            'cost_estimate': 500\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            'discrepancy': discrepancy,\n",
    "            'recommended_action': pattern['action'],\n",
    "            'resolution_template': pattern['template'],\n",
    "            'estimated_days': pattern['avg_resolution_days'],\n",
    "            'estimated_cost': pattern['cost_estimate'],\n",
    "            'auto_fixable': discrepancy.get('auto_fixable', False)\n",
    "        }\n",
    "    \n",
    "    def calculate_impact(self, discrepancies):\n",
    "        \"\"\"Calculate business impact of all discrepancies\"\"\"\n",
    "        total_cost = 0\n",
    "        total_days = 0\n",
    "        \n",
    "        resolutions = []\n",
    "        for disc in discrepancies:\n",
    "            resolution = self.recommend_resolution(disc)\n",
    "            resolutions.append(resolution)\n",
    "            total_cost += resolution['estimated_cost']\n",
    "            total_days = max(total_days, resolution['estimated_days'])\n",
    "        \n",
    "        return {\n",
    "            'resolutions': resolutions,\n",
    "            'total_estimated_cost': total_cost,\n",
    "            'max_resolution_days': total_days,\n",
    "            'n_auto_fixable': sum(1 for r in resolutions if r['auto_fixable'])\n",
    "        }\n",
    "\n",
    "# Initialize resolver\n",
    "resolver = DiscrepancyResolver()\n",
    "\n",
    "# Analyze resolution impact\n",
    "if all_discrepancies:\n",
    "    impact = resolver.calculate_impact(all_discrepancies)\n",
    "    \n",
    "    print(\"ðŸ“Š DISCREPANCY RESOLUTION ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total Discrepancies: {len(all_discrepancies)}\")\n",
    "    print(f\"Auto-fixable: {impact['n_auto_fixable']}\")\n",
    "    print(f\"\\nðŸ’° Estimated Resolution Cost: ${impact['total_estimated_cost']:,.0f}\")\n",
    "    print(f\"â±ï¸  Max Resolution Time: {impact['max_resolution_days']} days\")\n",
    "    \n",
    "    print(\"\\nðŸ“‹ RESOLUTION RECOMMENDATIONS:\")\n",
    "    print(\"-\" * 60)\n",
    "    for res in impact['resolutions'][:5]:  # Show first 5\n",
    "        print(f\"\\n  Rule: {res['discrepancy']['rule']}\")\n",
    "        print(f\"  Action: {res['recommended_action']}\")\n",
    "        print(f\"  Cost: ${res['estimated_cost']} | Days: {res['estimated_days']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processing Time Analytics\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **How does AI reduce processing time?**\n",
    "> \n",
    "> | Process Step | Manual | With AI |\n",
    "> |-------------|--------|--------|\n",
    "> | Document Receipt | 1 day | Minutes |\n",
    "> | OCR/Digitization | 2-4 hours | 2-3 minutes |\n",
    "> | Field Extraction | 1-2 hours | Seconds |\n",
    "> | Cross-validation | 2-4 hours | Seconds |\n",
    "> | Discrepancy ID | 1-2 hours | Instant |\n",
    "> | **Total** | **1-2 days** | **<1 hour** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate processing time comparison\n",
    "n_transactions = 100\n",
    "\n",
    "processing_comparison = pd.DataFrame({\n",
    "    'Step': ['Document Receipt', 'OCR/Digitization', 'Field Extraction', \n",
    "             'Cross-validation', 'Discrepancy Detection', 'Resolution Routing'],\n",
    "    'Manual (hours)': [8, 3, 2, 3, 1.5, 1],\n",
    "    'AI-Assisted (hours)': [0.5, 0.05, 0.01, 0.01, 0.01, 0.02]\n",
    "})\n",
    "\n",
    "processing_comparison['Time Savings (%)'] = (\n",
    "    (processing_comparison['Manual (hours)'] - processing_comparison['AI-Assisted (hours)']) / \n",
    "    processing_comparison['Manual (hours)'] * 100\n",
    ").round(1)\n",
    "\n",
    "print(\"ðŸ“Š PROCESSING TIME COMPARISON (per transaction)\")\n",
    "print(\"=\" * 70)\n",
    "print(processing_comparison.to_string(index=False))\n",
    "print(f\"\\nâ±ï¸  TOTAL Manual: {processing_comparison['Manual (hours)'].sum():.1f} hours\")\n",
    "print(f\"âš¡ TOTAL AI-Assisted: {processing_comparison['AI-Assisted (hours)'].sum():.2f} hours\")\n",
    "print(f\"ðŸ’° Time Savings: {(1 - processing_comparison['AI-Assisted (hours)'].sum()/processing_comparison['Manual (hours)'].sum())*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize processing comparison\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Manual',\n",
    "    x=processing_comparison['Step'],\n",
    "    y=processing_comparison['Manual (hours)'],\n",
    "    marker_color='indianred'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='AI-Assisted',\n",
    "    x=processing_comparison['Step'],\n",
    "    y=processing_comparison['AI-Assisted (hours)'],\n",
    "    marker_color='seagreen'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Trade Finance Processing Time: Manual vs AI-Assisted',\n",
    "    yaxis_title='Hours per Transaction',\n",
    "    barmode='group',\n",
    "    height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Executive Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create executive dashboard\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=(\n",
    "        'Document Volume by Type', 'Compliance Rate', 'Processing Pipeline',\n",
    "        'Discrepancy Trend', 'Cost Savings', 'SLA Performance'\n",
    "    ),\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"indicator\"}, {\"type\": \"funnel\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"bar\"}, {\"type\": \"indicator\"}]]\n",
    ")\n",
    "\n",
    "# 1. Document volume by type\n",
    "doc_counts = documents['document_type'].value_counts()\n",
    "fig.add_trace(go.Pie(labels=doc_counts.index, values=doc_counts.values, hole=0.4), row=1, col=1)\n",
    "\n",
    "# 2. Compliance rate gauge\n",
    "compliance_rate = validation_df['is_compliant'].mean() * 100\n",
    "fig.add_trace(go.Indicator(\n",
    "    mode=\"gauge+number\",\n",
    "    value=compliance_rate,\n",
    "    title={'text': \"First-Pass Compliance\"},\n",
    "    gauge={'axis': {'range': [0, 100]},\n",
    "           'bar': {'color': \"green\" if compliance_rate > 50 else \"red\"},\n",
    "           'threshold': {'line': {'color': \"black\", 'width': 4}, 'value': 50}}\n",
    "), row=1, col=2)\n",
    "\n",
    "# 3. Processing funnel\n",
    "fig.add_trace(go.Funnel(\n",
    "    y=['Received', 'Digitized', 'Extracted', 'Validated', 'Approved'],\n",
    "    x=[100, 100, 98, 95, int(compliance_rate)],\n",
    "    textinfo=\"value+percent initial\"\n",
    "), row=1, col=3)\n",
    "\n",
    "# 4. Discrepancy trend (simulated)\n",
    "dates = pd.date_range(end=datetime.now(), periods=30, freq='D')\n",
    "disc_trend = np.random.poisson(5, 30) + np.linspace(8, 3, 30)  # Declining trend\n",
    "fig.add_trace(go.Scatter(x=dates, y=disc_trend, mode='lines+markers', name='Discrepancies'), row=2, col=1)\n",
    "\n",
    "# 5. Cost savings\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\n",
    "savings = [15000, 22000, 28000, 35000, 42000, 48000]\n",
    "fig.add_trace(go.Bar(x=months, y=savings, marker_color='green'), row=2, col=2)\n",
    "\n",
    "# 6. SLA gauge\n",
    "sla_performance = 94.5\n",
    "fig.add_trace(go.Indicator(\n",
    "    mode=\"gauge+number+delta\",\n",
    "    value=sla_performance,\n",
    "    title={'text': \"SLA Met %\"},\n",
    "    delta={'reference': 95},\n",
    "    gauge={'axis': {'range': [80, 100]},\n",
    "           'bar': {'color': \"darkblue\"},\n",
    "           'steps': [{'range': [80, 90], 'color': 'lightgray'},\n",
    "                     {'range': [90, 95], 'color': 'gray'}]}\n",
    "), row=2, col=3)\n",
    "\n",
    "fig.update_layout(height=600, title_text='Trade Finance Operations Dashboard', showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways\n",
    "\n",
    "### AI Technologies for Trade Finance\n",
    "\n",
    "| Technology | Application | Benefit |\n",
    "|-----------|-------------|--------|\n",
    "| **OCR** | Document digitization | 99%+ accuracy on typed text |\n",
    "| **NER** | Field extraction | Automated data capture |\n",
    "| **Rules Engine** | Compliance checking | Consistent validation |\n",
    "| **ML Classification** | Discrepancy prediction | Proactive resolution |\n",
    "| **LLM** | Resolution recommendations | Expert-level guidance |\n",
    "\n",
    "### Business Impact\n",
    "\n",
    "| Metric | Before AI | After AI | Improvement |\n",
    "|--------|-----------|----------|-------------|\n",
    "| Processing time | 2-3 days | <1 hour | **97%** |\n",
    "| First-pass compliance | 35% | 65% | **86%** |\n",
    "| Cost per document | $50 | $12 | **76%** |\n",
    "| Discrepancy detection | Hours | Seconds | **99%** |\n",
    "\n",
    "### Implementation Considerations\n",
    "\n",
    "âš ï¸ **Important Notes:**\n",
    "- OCR accuracy depends on document quality\n",
    "- Human review required for edge cases\n",
    "- Integration with bank systems needed\n",
    "- Regulatory compliance (UCP 600) must be maintained\n",
    "\n",
    "---\n",
    "\n",
    "*Author: Ozgur Guler (ozgur.guler1@gmail.com)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
