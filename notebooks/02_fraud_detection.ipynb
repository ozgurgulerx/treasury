{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Payment Fraud Detection for Treasury\n",
    "\n",
    "## Use Case Overview\n",
    "\n",
    "**Business Problem:** Treasury processes millions of dollars in payments daily. Fraudulent payments can result from:\n",
    "- Business Email Compromise (BEC)\n",
    "- Invoice manipulation\n",
    "- Unauthorized payments\n",
    "- Sanctions violations\n",
    "\n",
    "**Impact:** The US Treasury reported preventing **$4+ billion in fraud** using ML in 2024.\n",
    "\n",
    "---\n",
    "\n",
    "## Detection Approaches\n",
    "\n",
    "| Approach | Method | Use Case |\n",
    "|----------|--------|----------|\n",
    "| **Rules-Based** | Static thresholds | Known fraud patterns |\n",
    "| **Anomaly Detection** | Isolation Forest, Autoencoders | Unknown/novel fraud |\n",
    "| **Supervised ML** | XGBoost, Neural Networks | When labeled data exists |\n",
    "| **Hybrid** | Rules + ML | Production systems |\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Generate payment data with realistic fraud patterns\n",
    "2. Build rules-based fraud detection\n",
    "3. Implement Isolation Forest for anomaly detection\n",
    "4. Combine approaches into a hybrid system\n",
    "5. Evaluate with precision, recall, and ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ML\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    precision_recall_curve, roc_curve, auc,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.treasury_sim.generators import generate_payments, set_seed\n",
    "\n",
    "print(\"âœ… Custom generators loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Payment Data with Fraud Labels\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **Fraud patterns we're simulating:**\n",
    "> \n",
    "> | Pattern | Description | Real-World Example |\n",
    "> |---------|-------------|--------------------|\n",
    "> | **Unusual Amount** | 5-20x normal transaction | BEC requesting urgent large payment |\n",
    "> | **New Beneficiary** | Unknown/unverified recipient | Fake vendor setup |\n",
    "> | **High-Risk Country** | Sanctioned or high-risk jurisdiction | Sanctions violation |\n",
    "> | **Unusual Time** | Outside business hours | Compromised credentials |\n",
    "> | **Round Amount** | Suspiciously round numbers | Invoice manipulation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 6 months of payment data\n",
    "set_seed(42)\n",
    "\n",
    "payments = generate_payments(\n",
    "    days=180,\n",
    "    daily_count=100,\n",
    "    anomaly_rate=0.03,  # 3% fraud rate\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Generated {len(payments):,} payments\")\n",
    "print(f\"ðŸš¨ Anomalies: {payments['is_anomaly'].sum()} ({payments['is_anomaly'].mean()*100:.1f}%)\")\n",
    "print(f\"\\nðŸ“… Date range: {payments['timestamp'].min().date()} to {payments['timestamp'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "print(\"=\" * 70)\n",
    "print(\"PAYMENT DATA SAMPLE\")\n",
    "print(\"=\" * 70)\n",
    "payments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly breakdown\n",
    "print(\"\\nðŸš¨ ANOMALY TYPES BREAKDOWN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "anomalies = payments[payments['is_anomaly']]\n",
    "all_reasons = []\n",
    "for reasons in anomalies['anomaly_reasons'].dropna():\n",
    "    all_reasons.extend(reasons.split('|'))\n",
    "\n",
    "reason_counts = pd.Series(all_reasons).value_counts()\n",
    "print(reason_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **What distinguishes fraudulent payments?**\n",
    "> 1. **Amount distribution** - Fraudulent payments are often outliers\n",
    "> 2. **Timing patterns** - Outside normal business hours\n",
    "> 3. **Beneficiary patterns** - New or unusual recipients\n",
    "> 4. **Geographic patterns** - High-risk countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add derived features for analysis\n",
    "payments['hour'] = payments['timestamp'].dt.hour\n",
    "payments['day_of_week'] = payments['timestamp'].dt.dayofweek\n",
    "payments['is_business_hours'] = payments['hour'].between(9, 17)\n",
    "payments['log_amount'] = np.log1p(payments['amount'])\n",
    "\n",
    "# Amount statistics by fraud status\n",
    "print(\"ðŸ’° AMOUNT STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(payments.groupby('is_anomaly')['amount'].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Amount Distribution (Log Scale)',\n",
    "        'Payments by Hour (Fraud Highlighted)',\n",
    "        'Country Distribution',\n",
    "        'Anomaly Score Distribution'\n",
    "    )\n",
    ")\n",
    "\n",
    "# 1. Amount distribution\n",
    "for is_fraud, color, name in [(False, 'blue', 'Normal'), (True, 'red', 'Anomaly')]:\n",
    "    subset = payments[payments['is_anomaly'] == is_fraud]\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=subset['log_amount'], name=name, opacity=0.7,\n",
    "                    marker_color=color, nbinsx=50),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# 2. Hourly distribution\n",
    "hourly = payments.groupby(['hour', 'is_anomaly']).size().unstack(fill_value=0)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=hourly.index, y=hourly[False], name='Normal', marker_color='blue'),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=hourly.index, y=hourly[True], name='Anomaly', marker_color='red'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Country distribution\n",
    "country_fraud = payments.groupby(['beneficiary_country', 'is_anomaly']).size().unstack(fill_value=0)\n",
    "country_fraud['fraud_rate'] = country_fraud[True] / (country_fraud[True] + country_fraud[False]) * 100\n",
    "country_fraud = country_fraud.sort_values('fraud_rate', ascending=True)\n",
    "fig.add_trace(\n",
    "    go.Bar(y=country_fraud.index, x=country_fraud['fraud_rate'], \n",
    "           orientation='h', name='Fraud Rate %', marker_color='orange'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Anomaly score\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=payments['anomaly_score'], nbinsx=20, \n",
    "                name='Anomaly Score', marker_color='purple'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=700, title_text='Payment Fraud - Exploratory Analysis', barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Key EDA Insights\n",
    "\n",
    "1. **Amount**: Fraudulent payments show higher amounts (right tail of distribution)\n",
    "2. **Timing**: Some anomalies occur outside business hours (before 9am, after 6pm)\n",
    "3. **Geography**: High-risk countries (RU, IR, KP, etc.) have 100% fraud rate\n",
    "4. **Multiple signals**: Many frauds trigger multiple anomaly reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Approach 1: Rules-Based Detection\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **Why start with rules?**\n",
    "> - **Interpretable**: Easy to explain to auditors/compliance\n",
    "> - **Fast**: No training required\n",
    "> - **Deterministic**: Same input = same output\n",
    "> - **Domain knowledge**: Captures known fraud patterns\n",
    ">\n",
    "> **Rules we'll implement:**\n",
    "> 1. Amount > $500,000 (large payment)\n",
    "> 2. High-risk country\n",
    "> 3. Outside business hours (before 8am or after 7pm)\n",
    "> 4. New beneficiary (contains 'NEW')\n",
    "> 5. Round amount (divisible by 10,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules_based_detection(df):\n",
    "    \"\"\"\n",
    "    Apply rules-based fraud detection.\n",
    "    \n",
    "    Returns DataFrame with rule flags and overall risk score.\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Define high-risk countries\n",
    "    high_risk_countries = ['RU', 'IR', 'KP', 'SY', 'VE', 'CU', 'XX']\n",
    "    \n",
    "    # Rule 1: Large amount\n",
    "    result['rule_large_amount'] = result['amount'] > 500000\n",
    "    \n",
    "    # Rule 2: High-risk country\n",
    "    result['rule_high_risk_country'] = result['beneficiary_country'].isin(high_risk_countries)\n",
    "    \n",
    "    # Rule 3: Outside business hours\n",
    "    result['rule_unusual_time'] = ~result['hour'].between(8, 19)\n",
    "    \n",
    "    # Rule 4: New beneficiary\n",
    "    result['rule_new_beneficiary'] = result['beneficiary_name'].str.contains('NEW', na=False)\n",
    "    \n",
    "    # Rule 5: Round amount\n",
    "    result['rule_round_amount'] = (result['amount'] % 10000 == 0) & (result['amount'] > 50000)\n",
    "    \n",
    "    # Calculate risk score (number of rules triggered)\n",
    "    rule_columns = [col for col in result.columns if col.startswith('rule_')]\n",
    "    result['rules_risk_score'] = result[rule_columns].sum(axis=1)\n",
    "    \n",
    "    # Flag as suspicious if any rule triggered\n",
    "    result['rules_flagged'] = result['rules_risk_score'] > 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply rules\n",
    "payments_rules = rules_based_detection(payments)\n",
    "\n",
    "# Evaluate rules-based approach\n",
    "print(\"ðŸ“‹ RULES-BASED DETECTION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nPayments flagged: {payments_rules['rules_flagged'].sum()} ({payments_rules['rules_flagged'].mean()*100:.1f}%)\")\n",
    "print(f\"Actual anomalies: {payments_rules['is_anomaly'].sum()} ({payments_rules['is_anomaly'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules performance metrics\n",
    "y_true = payments_rules['is_anomaly'].astype(int)\n",
    "y_pred_rules = payments_rules['rules_flagged'].astype(int)\n",
    "\n",
    "print(\"\\nðŸ“Š RULES-BASED PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_true, y_pred_rules, target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_rules = confusion_matrix(y_true, y_pred_rules)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(cm_rules, \n",
    "                   index=['Actual Normal', 'Actual Anomaly'],\n",
    "                   columns=['Pred Normal', 'Pred Anomaly']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-by-rule analysis\n",
    "rule_columns = [col for col in payments_rules.columns if col.startswith('rule_')]\n",
    "\n",
    "rule_stats = []\n",
    "for rule in rule_columns:\n",
    "    triggered = payments_rules[rule].sum()\n",
    "    true_positives = ((payments_rules[rule]) & (payments_rules['is_anomaly'])).sum()\n",
    "    precision = true_positives / triggered if triggered > 0 else 0\n",
    "    recall = true_positives / payments_rules['is_anomaly'].sum()\n",
    "    \n",
    "    rule_stats.append({\n",
    "        'Rule': rule.replace('rule_', '').replace('_', ' ').title(),\n",
    "        'Triggered': triggered,\n",
    "        'True Positives': true_positives,\n",
    "        'Precision': f\"{precision:.1%}\",\n",
    "        'Recall': f\"{recall:.1%}\"\n",
    "    })\n",
    "\n",
    "print(\"\\nðŸ“‹ RULE-BY-RULE PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(pd.DataFrame(rule_stats).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Approach 2: Isolation Forest (Anomaly Detection)\n",
    "\n",
    "### How Isolation Forest Works\n",
    "\n",
    "Isolation Forest detects anomalies by **isolating** observations:\n",
    "\n",
    "1. **Build trees**: Randomly select features and split values\n",
    "2. **Measure isolation**: Anomalies are easier to isolate (fewer splits needed)\n",
    "3. **Score**: Average path length across all trees\n",
    "\n",
    "$$s(x, n) = 2^{-\\frac{E(h(x))}{c(n)}}$$\n",
    "\n",
    "Where:\n",
    "- $h(x)$ = path length for observation $x$\n",
    "- $c(n)$ = average path length for $n$ samples\n",
    "- Score close to 1 = anomaly\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **Feature engineering for Isolation Forest:**\n",
    "> - Numerical features only (encode categoricals)\n",
    "> - Scale features for better performance\n",
    "> - Include behavioral features (amount relative to history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for Isolation Forest\n",
    "def prepare_features(df):\n",
    "    \"\"\"\n",
    "    Engineer features for anomaly detection.\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Amount features\n",
    "    features['amount'] = df['amount']\n",
    "    features['log_amount'] = np.log1p(df['amount'])\n",
    "    \n",
    "    # Time features\n",
    "    features['hour'] = df['timestamp'].dt.hour\n",
    "    features['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    features['is_business_hours'] = df['timestamp'].dt.hour.between(9, 17).astype(int)\n",
    "    \n",
    "    # Encode currency\n",
    "    le_currency = LabelEncoder()\n",
    "    features['currency_encoded'] = le_currency.fit_transform(df['currency'])\n",
    "    \n",
    "    # Encode country (with risk weighting)\n",
    "    high_risk = ['RU', 'IR', 'KP', 'SY', 'VE', 'CU', 'XX']\n",
    "    features['is_high_risk_country'] = df['beneficiary_country'].isin(high_risk).astype(int)\n",
    "    \n",
    "    # New beneficiary flag\n",
    "    features['is_new_beneficiary'] = df['beneficiary_name'].str.contains('NEW', na=False).astype(int)\n",
    "    \n",
    "    # Round amount flag\n",
    "    features['is_round_amount'] = ((df['amount'] % 10000 == 0) & (df['amount'] > 10000)).astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Prepare features\n",
    "X = prepare_features(payments)\n",
    "y = payments['is_anomaly'].astype(int)\n",
    "\n",
    "print(f\"ðŸ“Š Feature matrix shape: {X.shape}\")\n",
    "print(f\"\\nFeatures used:\")\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.03,  # Expected fraud rate\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"ðŸ”§ Training Isolation Forest...\")\n",
    "iso_forest.fit(X_scaled)\n",
    "\n",
    "# Get predictions and scores\n",
    "# Isolation Forest returns -1 for anomalies, 1 for normal\n",
    "predictions_if = iso_forest.predict(X_scaled)\n",
    "scores_if = -iso_forest.score_samples(X_scaled)  # Higher = more anomalous\n",
    "\n",
    "# Convert to binary (1 = anomaly)\n",
    "y_pred_if = (predictions_if == -1).astype(int)\n",
    "\n",
    "print(\"âœ… Isolation Forest trained!\")\n",
    "print(f\"\\nAnomalies detected: {y_pred_if.sum()} ({y_pred_if.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Isolation Forest\n",
    "print(\"\\nðŸ“Š ISOLATION FOREST PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y, y_pred_if, target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_if = confusion_matrix(y, y_pred_if)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(cm_if, \n",
    "                   index=['Actual Normal', 'Actual Anomaly'],\n",
    "                   columns=['Pred Normal', 'Pred Anomaly']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scores to dataframe\n",
    "payments_rules['if_score'] = scores_if\n",
    "payments_rules['if_flagged'] = y_pred_if\n",
    "\n",
    "# Visualize score distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=payments_rules[~payments_rules['is_anomaly']]['if_score'],\n",
    "    name='Normal', opacity=0.7, nbinsx=50\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=payments_rules[payments_rules['is_anomaly']]['if_score'],\n",
    "    name='Anomaly', opacity=0.7, nbinsx=50\n",
    "))\n",
    "\n",
    "# Add threshold line\n",
    "threshold = np.percentile(scores_if, 97)  # Top 3%\n",
    "fig.add_vline(x=threshold, line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=\"Detection Threshold\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Isolation Forest Anomaly Scores',\n",
    "    xaxis_title='Anomaly Score (higher = more suspicious)',\n",
    "    yaxis_title='Count',\n",
    "    barmode='overlay',\n",
    "    height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Approach 3: Hybrid System\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **Why combine approaches?**\n",
    "> - Rules catch **known patterns** with high confidence\n",
    "> - ML catches **novel patterns** that rules miss\n",
    "> - Ensemble reduces false positives\n",
    ">\n",
    "> **Combination strategy:**\n",
    "> - **High Alert**: Rules OR high ML score\n",
    "> - **Medium Alert**: Rules XOR moderate ML score\n",
    "> - **Low Alert**: Only ML flagged (below threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_detection(df, if_threshold_percentile=95):\n",
    "    \"\"\"\n",
    "    Combine rules and ML for hybrid fraud detection.\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Calculate IF threshold\n",
    "    if_threshold = np.percentile(result['if_score'], if_threshold_percentile)\n",
    "    \n",
    "    # Scoring: Combine rules and ML\n",
    "    result['hybrid_score'] = (\n",
    "        result['rules_risk_score'] * 0.4 +  # Rules contribution\n",
    "        (result['if_score'] / result['if_score'].max()) * 3 * 0.6  # ML contribution (normalized)\n",
    "    )\n",
    "    \n",
    "    # Risk levels\n",
    "    conditions = [\n",
    "        (result['rules_risk_score'] >= 2) | (result['if_score'] > np.percentile(result['if_score'], 99)),\n",
    "        (result['rules_risk_score'] >= 1) | (result['if_score'] > np.percentile(result['if_score'], 97)),\n",
    "        (result['if_score'] > np.percentile(result['if_score'], 95)),\n",
    "    ]\n",
    "    choices = ['HIGH', 'MEDIUM', 'LOW']\n",
    "    result['risk_level'] = np.select(conditions, choices, default='NORMAL')\n",
    "    \n",
    "    # Binary flag for evaluation\n",
    "    result['hybrid_flagged'] = result['risk_level'] != 'NORMAL'\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply hybrid detection\n",
    "payments_hybrid = hybrid_detection(payments_rules)\n",
    "\n",
    "print(\"ðŸ“Š HYBRID DETECTION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nRisk Level Distribution:\")\n",
    "print(payments_hybrid['risk_level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate hybrid approach\n",
    "y_pred_hybrid = payments_hybrid['hybrid_flagged'].astype(int)\n",
    "\n",
    "print(\"\\nðŸ“Š HYBRID SYSTEM PERFORMANCE\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y, y_pred_hybrid, target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_hybrid = confusion_matrix(y, y_pred_hybrid)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(cm_hybrid, \n",
    "                   index=['Actual Normal', 'Actual Anomaly'],\n",
    "                   columns=['Pred Normal', 'Pred Anomaly']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all approaches\n",
    "def evaluate_model(y_true, y_pred, name):\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'False Positives': ((y_pred == 1) & (y_true == 0)).sum(),\n",
    "        'False Negatives': ((y_pred == 0) & (y_true == 1)).sum()\n",
    "    }\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    evaluate_model(y, y_pred_rules, 'Rules-Based'),\n",
    "    evaluate_model(y, y_pred_if, 'Isolation Forest'),\n",
    "    evaluate_model(y, y_pred_hybrid, 'Hybrid System')\n",
    "])\n",
    "\n",
    "print(\"ðŸ“Š MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Precision vs Recall', 'False Positives vs False Negatives')\n",
    ")\n",
    "\n",
    "colors = ['#636EFA', '#EF553B', '#00CC96']\n",
    "\n",
    "# Precision vs Recall\n",
    "fig.add_trace(\n",
    "    go.Bar(x=comparison['Model'], y=comparison['Precision'], \n",
    "           name='Precision', marker_color=colors[0]),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=comparison['Model'], y=comparison['Recall'], \n",
    "           name='Recall', marker_color=colors[1]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# False Positives vs False Negatives\n",
    "fig.add_trace(\n",
    "    go.Bar(x=comparison['Model'], y=comparison['False Positives'], \n",
    "           name='False Positives', marker_color='orange', showlegend=True),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=comparison['Model'], y=comparison['False Negatives'], \n",
    "           name='False Negatives', marker_color='red', showlegend=True),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400, title_text='Fraud Detection Model Comparison', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Production Alert Dashboard (Mockup)\n",
    "\n",
    "### Thinking Trace ðŸ§ \n",
    "\n",
    "> **What would a production system look like?**\n",
    "> - Real-time payment scoring\n",
    "> - Alert queue for review\n",
    "> - Risk-based prioritization\n",
    "> - Audit trail for compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alert dashboard view\n",
    "alerts = payments_hybrid[payments_hybrid['risk_level'] != 'NORMAL'].copy()\n",
    "alerts = alerts.sort_values('hybrid_score', ascending=False)\n",
    "\n",
    "# Select columns for display\n",
    "alert_display = alerts[[\n",
    "    'payment_id', 'timestamp', 'amount', 'currency',\n",
    "    'beneficiary_name', 'beneficiary_country',\n",
    "    'risk_level', 'hybrid_score', 'anomaly_reasons'\n",
    "]].head(20)\n",
    "\n",
    "print(\"ðŸš¨ FRAUD ALERT DASHBOARD\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nTotal Alerts: {len(alerts)}\")\n",
    "print(f\"  HIGH:   {(alerts['risk_level'] == 'HIGH').sum()}\")\n",
    "print(f\"  MEDIUM: {(alerts['risk_level'] == 'MEDIUM').sum()}\")\n",
    "print(f\"  LOW:    {(alerts['risk_level'] == 'LOW').sum()}\")\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"\\nTOP 20 ALERTS (by risk score):\")\n",
    "alert_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alert summary visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Alerts by Risk Level',\n",
    "        'Alert Amount Distribution',\n",
    "        'Alerts by Country',\n",
    "        'Daily Alert Trend'\n",
    "    ),\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"histogram\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "# 1. Pie chart - risk levels\n",
    "risk_counts = alerts['risk_level'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=risk_counts.index, values=risk_counts.values,\n",
    "           marker_colors=['red', 'orange', 'yellow']),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Amount distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=alerts['amount'], nbinsx=30, marker_color='red'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. By country\n",
    "country_alerts = alerts['beneficiary_country'].value_counts().head(10)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=country_alerts.index, y=country_alerts.values, marker_color='orange'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Daily trend\n",
    "daily_alerts = alerts.groupby(alerts['timestamp'].dt.date).size()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=daily_alerts.index, y=daily_alerts.values, mode='lines+markers'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600, title_text='Fraud Alert Dashboard', showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "### Model Selection Guide\n",
    "\n",
    "| Scenario | Recommended Approach | Rationale |\n",
    "|----------|---------------------|----------|\n",
    "| **Quick deployment** | Rules-Based | Fast, interpretable |\n",
    "| **Novel fraud types** | Isolation Forest | Detects unknown patterns |\n",
    "| **Production system** | Hybrid | Best of both worlds |\n",
    "| **Labeled historical data** | Supervised ML (XGBoost) | Higher accuracy |\n",
    "\n",
    "### Business Recommendations\n",
    "\n",
    "1. **Start with rules** for immediate protection\n",
    "2. **Add ML layer** to catch what rules miss\n",
    "3. **Tune thresholds** based on operational capacity\n",
    "4. **Track false positives** to maintain trust in the system\n",
    "5. **Human review** for high-risk alerts (never auto-block)\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "| Aspect | Implementation |\n",
    "|--------|----------------|\n",
    "| **Latency** | <100ms for real-time scoring |\n",
    "| **Feedback loop** | Incorporate investigation outcomes |\n",
    "| **Model refresh** | Retrain monthly with new data |\n",
    "| **Explainability** | Log which rules/features triggered |\n",
    "| **Audit trail** | Store all decisions for compliance |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Notebook created for Treasury AI educational purposes*\n",
    "\n",
    "*Author: Ozgur Guler (ozgur.guler1@gmail.com)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
